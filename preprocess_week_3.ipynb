{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this week we will make simple time-serie prediction model. Before dealing with this problem we are going to create .pickle files with  aggregated data coordinates: regions-hours. Numbers in table cells are the amount of taxi trips. Do all this stuff for six month of 2014. Later in this project we will work with data collected for 2 year period, but now we pick just half of the 2014 year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### all .csv files were gathered from source specified in week_1 task or notebook related to first week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mypath = \"H:/Yandex machine learning/finall course coursera/csv_yellow_cab_2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yellow_tripdata_2014-12.csv', 'yellow_tripdata_2014-11.csv', 'yellow_tripdata_2014-10.csv', 'yellow_tripdata_2014-09.csv', 'yellow_tripdata_2014-08.csv', 'yellow_tripdata_2014-07.csv', 'yellow_tripdata_2014-06.csv', 'yellow_tripdata_2014-05.csv']\n"
     ]
    }
   ],
   "source": [
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NY_long_west = -74.25559\n",
    "NY_long_east = -73.70001\n",
    "NY_latt_south = 40.49612\n",
    "NY_latt_north = 40.91553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_counter(longitude, latitude):\n",
    "    long_num = np.ceil((longitude - NY_long_west)*50.0/(NY_long_east - NY_long_west))\n",
    "    lat_num = np.ceil((latitude - NY_latt_south)*50.0/(NY_latt_north - NY_latt_south))\n",
    "    \n",
    "    return (long_num - 1) * 50.0 + lat_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow_tripdata_2014-05.csv\n",
      "yellow_tripdata_2014-05.csv  start num of trips:  14774041\n",
      "yellow_tripdata_2014-05.csv  final num of trips:  14344559\n",
      "yellow_tripdata_2014-05.csv  null values:  False\n"
     ]
    }
   ],
   "source": [
    "for file in onlyfiles[7:]:\n",
    "    print(file)\n",
    "    \n",
    "    ''' for modified csv file '''\n",
    "    #taxi = pd.read_csv(mypath + \"/\" + file, sep='\\t', usecols=[\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \n",
    "    #                                                 \"passenger_count\", \"trip_distance\",\"pickup_longitude\", \"pickup_latitude\"])\n",
    "    if \"2014\" in re.findall(\"[-+]?[.]?[\\d]+(?:,\\d\\d\\d)*[\\.]?\\d*(?:[eE][-+]?\\d+)?\", file):\n",
    "        taxi = pd.read_csv(mypath + \"/\" + file, usecols=[\" pickup_datetime\", \" dropoff_datetime\", \n",
    "                                                     \" passenger_count\", \" trip_distance\", \" pickup_longitude\", \" pickup_latitude\"])\n",
    "        taxi.rename(index=str, columns={\" pickup_datetime\": \"tpep_pickup_datetime\", \n",
    "                                        \" dropoff_datetime\": \"tpep_dropoff_datetime\", \" passenger_count\": \"passenger_count\", \n",
    "                                        \" trip_distance\": \"trip_distance\", \" pickup_longitude\": \"pickup_longitude\", \n",
    "                                        \" pickup_latitude\": \"pickup_latitude\"}, inplace=True)\n",
    "    else:\n",
    "        taxi = pd.read_csv(mypath + \"/\" + file, usecols=[\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \n",
    "                                                     \"passenger_count\", \"trip_distance\",\"pickup_longitude\", \"pickup_latitude\"])\n",
    "        \n",
    "    print(file, \" start num of trips: \", taxi.shape[0])\n",
    "    taxi.drop(taxi[taxi.passenger_count == 0].index, inplace=True)\n",
    "    taxi.drop(taxi[taxi.trip_distance == 0].index, inplace=True)\n",
    "    taxi.drop(taxi[taxi.tpep_pickup_datetime == taxi.tpep_dropoff_datetime].index, inplace=True)\n",
    "    taxi.drop(taxi[taxi.pickup_longitude < -74.25559].index, inplace=True)\n",
    "    taxi.drop(taxi[taxi.pickup_longitude > -73.70001].index, inplace=True)\n",
    "    taxi.drop(taxi[taxi.pickup_latitude < 40.49612].index, inplace=True)\n",
    "    taxi.drop(taxi[taxi.pickup_latitude > 40.91553].index, inplace=True)\n",
    "    columns = ['passenger_count','trip_distance', 'pickup_longitude', 'pickup_latitude']\n",
    "    null_val = taxi[columns].isnull().values.any()\n",
    "    print(file, \" final num of trips: \", taxi.shape[0])\n",
    "    print(file, \" null values: \", null_val)\n",
    "    if null_val:\n",
    "        taxi = taxi[np.isfinite(df[columns])]\n",
    "        print(file, \" after droping NaNs num of trips: \", taxi.shape[0])\n",
    "    taxi[\"region\"] = region_counter(taxi.pickup_longitude, taxi.pickup_latitude)\n",
    "    taxi[\"hour_statistic\"] = pd.DatetimeIndex(taxi.tpep_pickup_datetime).map(lambda x: x.replace(minute=0, second=0))\n",
    "    hours_in_month = np.sort(np.unique(taxi.hour_statistic)).astype(np.int64)\n",
    "    hours_in_month = np.hstack((hours_in_month, hours_in_month[-1] + 3600000000000)) #add last hour\n",
    "    \n",
    "    region_bined_stat = stats.binned_statistic_2d(taxi.region, taxi.hour_statistic.astype(np.int64), \n",
    "                                            \"None\", 'count', bins=[np.arange(1, 2502), hours_in_month])\n",
    "    \n",
    "    file_name = \"reg_bin_stat_\" + re.findall(\"\\d+\\-\\d+\", file)[0] + \".pkl\"\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(region_bined_stat.statistic, f)\n",
    "    \n",
    "    # These are the usual ipython objects, including this one you are creating\n",
    "    ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "    #print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    del(taxi)  \n",
    "    del(region_bined_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this code helps to reduce size of original .csv files. Original files have quite big size (2 Gb each)and it may case problems on machines with low RAM.  We just do:int64=>int, float64=>float transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi = pd.read_csv(mypath + \"/\" + 'yellow_tripdata_2015-06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12324935 entries, 0 to 12324934\n",
      "Data columns (total 19 columns):\n",
      "VendorID                 int64\n",
      "tpep_pickup_datetime     object\n",
      "tpep_dropoff_datetime    object\n",
      "passenger_count          int64\n",
      "trip_distance            float64\n",
      "pickup_longitude         float64\n",
      "pickup_latitude          float64\n",
      "RateCodeID               int64\n",
      "store_and_fwd_flag       object\n",
      "dropoff_longitude        float64\n",
      "dropoff_latitude         float64\n",
      "payment_type             int64\n",
      "fare_amount              float64\n",
      "extra                    float64\n",
      "mta_tax                  float64\n",
      "tip_amount               float64\n",
      "tolls_amount             float64\n",
      "improvement_surcharge    float64\n",
      "total_amount             float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 1.7+ GB\n"
     ]
    }
   ],
   "source": [
    "taxi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'RateCodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(taxi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4019.86 MB\n"
     ]
    }
   ],
   "source": [
    "print(mem_usage(taxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi.loc[:, taxi.dtypes == np.int64] = taxi.loc[:, taxi.dtypes == np.int64].apply(pd.to_numeric,downcast='unsigned')\n",
    "print(mem_usage(taxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi.loc[:, taxi.dtypes == np.float64] = taxi.loc[:, taxi.dtypes == np.float64].apply(pd.to_numeric,downcast='float')\n",
    "print(mem_usage(taxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi.to_csv(mypath + \"/\" + \"yellow_tripdata_2015-06_edit.csv\", sep='\\t', columns=list(taxi.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
